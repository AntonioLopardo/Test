{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import keras\n",
    "import pickle\n",
    "import json\n",
    "import os\n",
    "import random\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, LSTM, Dropout\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras import optimizers\n",
    "import re\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.6\n"
     ]
    }
   ],
   "source": [
    "print(keras.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "config = tf.ConfigProto( device_count = {'GPU': 1 , 'CPU': 4} ) \n",
    "sess = tf.Session(config=config) \n",
    "keras.backend.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.DataFrame([['fuck you, life is shitty', 0]], columns=['text', 'sent'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   A  B\n",
       "0  1  2"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame([[1, 2], [3, 4]], columns=list('AB'))\n",
    "df = df[df['B'] == 2]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/antoniolopardo/Desktop/myRNN/mySentRNN_v0.02/NewDataSet/:(\n",
      ":(_2018-01-04_to_2018-01-10.json\n",
      "(1504, 2)\n",
      ":(_2018-01-22_to_2018-01-28.json\n",
      "(3078, 2)\n",
      ":(_2018-01-18_to_2018-01-24.json\n",
      "(4603, 2)\n",
      ":(_2018-02-13_to_2018-02-19.json\n",
      "(5866, 2)\n",
      ":(_2018-01-11_to_2018-01-17.json\n",
      "(7427, 2)\n",
      ":(_2018-01-01_to_2018-01-07.json\n",
      "(8888, 2)\n",
      ":(_2017-12-31.json\n",
      "(8931, 2)\n",
      ":(_2017-12-24_to_2017-12-30.json\n",
      "(10221, 2)\n",
      ":(_2018-02-18_to_2018-02-24.json\n",
      "(11583, 2)\n",
      ":(_2018-01-06_to_2018-01-12.json\n",
      "(13046, 2)\n"
     ]
    }
   ],
   "source": [
    "def loadNeg(data):\n",
    "    local_data = data\n",
    "    os.chdir('/home/antoniolopardo/Desktop/myRNN/mySentRNN_v0.02/NewDataSet/:(')\n",
    "    print(os.getcwd())\n",
    "    for file in os.listdir():\n",
    "        print(file)\n",
    "        #start = int(data.shape[0])\n",
    "        with open(file, 'r') as f:\n",
    "            for line in f:\n",
    "                line_loaded = json.loads(line)\n",
    "                if line_loaded['text'][0:2] != 'RT' and len(line_loaded['text']) > 90:\n",
    "                    temp_df = pd.DataFrame([[line_loaded['text'], 0]], columns=['text', 'sent'])\n",
    "                    if random.uniform(0, 1) < 1:\n",
    "                        local_data = local_data.append(temp_df,  ignore_index=True)\n",
    "        print(local_data.shape)\n",
    "    return local_data\n",
    "data = loadNeg(data)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/antoniolopardo/Desktop/myRNN/mySentRNN_v0.02/NewDataSet/:)\n",
      ":)_2018-01-01_to_2018-01-07.json\n",
      "(15214, 2)\n",
      ":)_2018-02-18_to_2018-02-24.json\n",
      "(17277, 2)\n",
      ":)_2017-12-24_to_2017-12-30.json\n",
      "(19083, 2)\n",
      ":)_2018-01-18_to_2018-01-24.json\n",
      "(21403, 2)\n",
      ":)_2018-01-22_to_2018-01-28.json\n",
      "(23558, 2)\n",
      ":)_2018-01-04_to_2018-01-10.json\n",
      "(25649, 2)\n",
      ":)_2018-02-13_to_2018-02-19.json\n",
      "(26092, 2)\n",
      ":)_2017-12-31.json\n",
      "(26092, 2)\n",
      ":)_2018-01-11_to_2018-01-17.json\n",
      "(26092, 2)\n",
      ":)_2018-01-06_to_2018-01-12.json\n",
      "(26092, 2)\n",
      ":)_2018-01-09_to_2018-01-15.json\n",
      "(26092, 2)\n"
     ]
    }
   ],
   "source": [
    "def loadPos(data):\n",
    "    TotalDim = 2*data.shape[0]\n",
    "    local_data = data\n",
    "    os.chdir('/home/antoniolopardo/Desktop/myRNN/mySentRNN_v0.02/NewDataSet/:)')\n",
    "    print(os.getcwd())\n",
    "    new_json_files = [pos_json for pos_json in os.listdir(os.getcwd()) if pos_json.endswith('.json')]\n",
    "    #new_json_files = [os.getcwd()+ '/' + json_file for json_file in new_json_files]\n",
    "    for file in new_json_files:\n",
    "        print(file)\n",
    "        #start = int(data.shape[0])\n",
    "        with open(file, 'r') as f:\n",
    "            try:\n",
    "                for line in f:\n",
    "                    line_loaded = json.loads(line)\n",
    "                    if line_loaded['text'][0:2] != 'RT' and len(line_loaded['text']) > 90:\n",
    "                        temp_df = pd.DataFrame( [[line_loaded['text'], 1]], columns=['text', 'sent'])\n",
    "                        if local_data.shape[0] < TotalDim and random.uniform(0, 1) < 0.2:\n",
    "                            local_data = local_data.append(temp_df,  ignore_index=True)\n",
    "            except:\n",
    "                print('failed to load')\n",
    "        print(local_data.shape)\n",
    "    return local_data\n",
    "data = loadPos(data)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    39822\n",
      "0    31435\n",
      "Name: sent, dtype: int64\n",
      "8387\n",
      "1    16481\n",
      "0    16389\n",
      "Name: sent, dtype: int64\n",
      "0    15046\n",
      "1    14954\n",
      "Name: sent, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "os.chdir('/home/antoniolopardo/Desktop/myRNN/mySentRNN_v0.02')\n",
    "data_kaggle = pd.read_csv('KaggleTranslated.csv', encoding='latin_1', index_col = 0)\n",
    "data_kaggle = data_kaggle.rename(index=str, columns={\"SentimentText\": \"text\"})\n",
    "\n",
    "print(data_kaggle['sent'].value_counts())\n",
    "\n",
    "diff = abs(data_kaggle['sent'].value_counts()[0] - data_kaggle['sent'].value_counts()[1])\n",
    "print (diff)\n",
    "\n",
    "data_kaggle_pos = data_kaggle[data_kaggle['sent'] == 1]\n",
    "\n",
    "drop_indices = np.random.choice(data_kaggle_pos.index, diff, replace=False)\n",
    "\n",
    "data_kaggle = data_kaggle.drop(drop_indices)\n",
    "\n",
    "data_kaggle = data_kaggle.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "data_kaggle_test = data_kaggle[data_kaggle.index < 30000]\n",
    "data_kaggle_train = data_kaggle[data_kaggle.index >= 30000]\n",
    "    \n",
    "print(data_kaggle_train['sent'].value_counts())\n",
    "print(data_kaggle_test['sent'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0    2472\n",
      "1.0    1601\n",
      "Name: sent, dtype: int64\n",
      "871\n",
      "                                                   text  sent\n",
      "0     Intanto la partita per Via Nazionale si compli...   0.0\n",
      "1     False illusioni, sgradevoli realtÃ  Mario Mont...   0.0\n",
      "2     False illusioni, sgradevoli realtÃ  #editorial...   0.0\n",
      "3     Mario Monti: Berlusconi risparmi all'Italia il...   0.0\n",
      "4     Mario Monti: Berlusconi risparmi all'Italia il...   0.0\n",
      "6     L'attacco di Mario Monti al governo Berlusconi...   0.0\n",
      "7     Mario Monti sul Corriere: la fotografia piÃ¹ i...   1.0\n",
      "8     Le 5 sgradevoli realtÃ  di cui Berlusconi dovr...   0.0\n",
      "9     False illusioni, sgradevoli realtÃ : http://t....   0.0\n",
      "10    Mario Monti: c'Ã¨ il rischio... di trasformare...   0.0\n",
      "11    Ma a quanta gente DEMOCRATICA rode che la Bors...   0.0\n",
      "12    Mario Monti: False illusioni, sgradevoli realt...   0.0\n",
      "13    @mauryred82 l'ho letto quell'articolo in treno...   0.0\n",
      "14    Ascolti Mario Monti e ti chiedi.. PerchÃ© disp...   0.0\n",
      "15    #la7 ma perche' Mario Monti non fa il premier?...   0.0\n",
      "16    PerchÃ© non ha senso parlare di governo Monti,...   0.0\n",
      "17    Mario Monti Ã¨ conosciuto dal 60% degli interv...   0.0\n",
      "18    @riotta sono piu' tranquillo ora :-) buona gio...   1.0\n",
      "19    Mario #Monti: La lira non era una moneta stran...   0.0\n",
      "20    Mario Monti a Berlusconi, l'euro non Ã¨ in cri...   1.0\n",
      "21    Un parere autorevole e non demagogico sull'eur...   1.0\n",
      "23    Ma quanto ce vuole affinchÃ¨ Mario Monti arriv...   0.0\n",
      "24                          @riotta mario monti subito!   1.0\n",
      "25    #Italiaresiste Mario Monti subito Presidente d...   1.0\n",
      "27          @FGoria Mario Monti Premier! #Italiaresiste   1.0\n",
      "28        arriva il governo monti? http://t.co/TQ8z9OTn   NaN\n",
      "29    Bossi risponde con una pernacchia a un ipoteti...   0.0\n",
      "30    @riotta @DeBortoliF Al #G20 di Cannes circola ...   NaN\n",
      "31    Belle personcine: alle misure contro l'emergen...   NaN\n",
      "32            Mario Monti e Mario Draghi #Italiaresiste   NaN\n",
      "...                                                 ...   ...\n",
      "7376  Gay, il coming out fa bene alla salute: \\\"Dich...   NaN\n",
      "7377  Lasciamoci infuocare dall'Amore che sgorga dal...   1.0\n",
      "7378  Io vedo solo merli maschi qui da me. E la merl...   NaN\n",
      "7379  Ma il #palermo dove li mette tutti sti acquisti??   NaN\n",
      "7380  @EnzoQuareEQ7 un bel colpo marketing dopo il c...   NaN\n",
      "7381  #amomiamadreperchÃ© mi ha regalato 8 persone p...   1.0\n",
      "7382              @demisperfume wow grazie mille asdfgh   NaN\n",
      "7383  | E' quando ti accorgi di essere geloso anche ...   0.0\n",
      "7384  \\\"Il problema tuo e della tua famiglia Ã¨ che ...   NaN\n",
      "7385  Vendola: innamorato del mio compagno   sogno u...   NaN\n",
      "7386  @ehihotvato Scusa il disturbo,puoi inviare un ...   1.0\n",
      "7387  #amomiopadreperchÃ¨ beh leggendo tutti i tweet...   0.0\n",
      "7388  #rt seguimi e ti seguo e ti aggiungo alla mia ...   1.0\n",
      "7389  @__LoveLavigne Non ce la faccio piÃ¹. Ci lasci...   0.0\n",
      "7390  Fatevi dare un consiglio.Se ancora non lo siet...   NaN\n",
      "7391    @_AustinIsMyIdol grazie ** e grazie del follow!   1.0\n",
      "7392               @harrystoy sono della lista ricambi?   NaN\n",
      "7393  @JasmineGranata Anche quella Ã¨ una buona idea...   NaN\n",
      "7394  Ad Harry Styles:-sembrava ieri che cantavi 'is...   NaN\n",
      "7395  @FabioClerici sono altri a dire che Ã¨ un reat...   NaN\n",
      "7396  @harolds_voice @perriespowaah sai che Justin m...   1.0\n",
      "7397  @harry_styles scusa se a volte ti trascuro e n...   NaN\n",
      "7398  @LilithFanny ahahahah certamente... Anche tu l...   NaN\n",
      "7399  @exexvoto socio di una fondazione bancaria col...   NaN\n",
      "7400               Siamo a 50 #followers grazie a tutti   1.0\n",
      "7401  @Harry_Styles pensandoci bene Ã¨ il tuo second...   0.0\n",
      "7402  C'ero quando tutto questo successe per i tuoi ...   NaN\n",
      "7403  caro Mario Monti,se vai su e sistemi un pÃ² di...   1.0\n",
      "7406  Strepitoso il titolo in prima di Libero sul go...   1.0\n",
      "7407  @nataliacavalli Consolati, il governo #Monti h...   0.0\n",
      "\n",
      "[6889 rows x 2 columns]\n",
      "0.0    1701\n",
      "1.0    1601\n",
      "Name: sent, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "os.chdir('/home/antoniolopardo/Desktop/myRNN/mySentRNN_v0.02')\n",
    "data_pol = pd.read_csv('EvalItalia2016/training_set_sentipolc16.csv', encoding = \"latin_1\")\n",
    "del data_pol['idtwitter']\n",
    "del data_pol['iro']\n",
    "del data_pol['top']\n",
    "del data_pol['subj']\n",
    "#del data_pol['lpos']\n",
    "#del data_pol['lneg']\n",
    "\n",
    "#data_pol['sent'] = 6\n",
    "\n",
    "#data_pol['sent'] = 6\n",
    "data_pol = data_pol.drop(data_pol[(data_pol['opos'] == 1) & (data_pol['oneg'] == 1)].index)\n",
    "data_pol = data_pol.drop(data_pol[(data_pol['lpos'] == 1) & (data_pol['lneg'] == 1)].index)\n",
    "\n",
    "data_pol.loc[data_pol['lpos'] == 1, 'sent'] = 1\n",
    "data_pol.loc[data_pol['lneg'] == 1, 'sent'] = 0\n",
    "\n",
    "data_pol.loc[data_pol['opos'] == 1, 'sent'] = 1\n",
    "data_pol.loc[data_pol['oneg'] == 1, 'sent'] = 0\n",
    "\n",
    "\n",
    "data_pol = data_pol[['text','sent']]\n",
    "\n",
    "print(data_pol['sent'].value_counts())\n",
    "\n",
    "diff = data_pol['sent'].value_counts()[0] - data_pol['sent'].value_counts()[1]\n",
    "print (diff)\n",
    "print(data_pol)\n",
    "d_neg = data_pol[data_pol['sent'] == 0]\n",
    "\n",
    "drop_indices = np.random.choice(d_neg.index, diff-100, replace=False)\n",
    "\n",
    "data_pol = data_pol.drop(drop_indices)\n",
    "    \n",
    "print(data_pol['sent'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0    301\n",
      "0.0    299\n",
      "Name: sent, dtype: int64\n",
      "0.0    1402\n",
      "1.0    1300\n",
      "Name: sent, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "data_pol = data_pol.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "data_null = data_pol[np.isnan(data_pol['sent'])]\n",
    "drop_indices = np.random.choice(data_null.index, data_null.shape[0], replace=False)\n",
    "\n",
    "data_pol = data_pol.drop(drop_indices)\n",
    "\n",
    "data_pol = data_pol.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "data_pol_test = data_pol[data_pol.index < 600]\n",
    "data_pol_train = data_pol[data_pol.index >= 600]\n",
    "\n",
    "\n",
    "print(data_pol_test['sent'].value_counts())\n",
    "print(data_pol_train['sent'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0    19194\n",
      "1.0    19081\n",
      "Name: sent, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "data_pol = data_pol.sample(frac=1).reset_index(drop=True)\n",
    "data = data.append(data_kaggle_train,ignore_index=True)\n",
    "data = data.append(data_pol_train,  ignore_index=True)\n",
    "data = data.append(data_pol_train,  ignore_index=True)\n",
    "\n",
    "print(data['sent'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0    19194\n",
      "1.0    19081\n",
      "Name: sent, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "data['text'] = data['text'].apply(lambda x: x.lower())\n",
    "data['text'] = data['text'].apply((lambda x: re.sub('[^a-zA-z0-9\\s]','',x)))\n",
    "data['text'] = data['text'].apply((lambda x: re.sub(':\\)','',x)))\n",
    "data['text'] = data['text'].apply((lambda x: re.sub(':\\(','',x)))\n",
    "data['text'] = data['text'].apply((lambda x: re.sub('#','',x)))\n",
    "data['text'] = data['text'].apply((lambda x: re.sub('Berlusconi','akfha',x)))\n",
    "data['text'] = data['text'].apply((lambda x: re.sub('Renzi','lafh',x)))\n",
    "data['text'] = data['text'].apply((lambda x: re.sub('Salvini','kjahfka',x)))\n",
    "data['text'] = data['text'].apply((lambda x: re.sub('Grillo','lhalahfl',x)))\n",
    "data['text'] = data['text'].apply((lambda x: re.sub('berlusconi','akfha',x)))\n",
    "data['text'] = data['text'].apply((lambda x: re.sub('renzi','lafh',x)))\n",
    "data['text'] = data['text'].apply((lambda x: re.sub('salvini','kjahfka',x)))\n",
    "data['text'] = data['text'].apply((lambda x: re.sub('grillo','lhalahfl',x)))\n",
    "data['text'] = data['text'].apply((lambda x: re.sub('Lega','sds',x)))\n",
    "data['text'] = data['text'].apply((lambda x: re.sub('PD ','fsfsfsf',x)))\n",
    "data['text'] = data['text'].apply((lambda x: re.sub('FI ','dsgsgsgs',x)))\n",
    "\n",
    "print(data['sent'].value_counts())\n",
    "\n",
    "data = data.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "#for idx,row in data.iterrows():\n",
    " #   row[0] = row[0].replace('rt',' ')\n",
    "    \n",
    "max_features = 20000\n",
    "maxlen = 30\n",
    "tokenizer = Tokenizer(num_words=max_features, split=' ')\n",
    "tokenizer.fit_on_texts(data['text'].values)\n",
    "X = tokenizer.texts_to_sequences(data['text'].values)\n",
    "X = pad_sequences(X, maxlen=maxlen)\n",
    "\n",
    "tokenizer_f = open(\"tokenizer.pickle\", \"wb\")\n",
    "pickle.dump(tokenizer, tokenizer_f)\n",
    "tokenizer_f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#myopt=keras.optimizers.Adagrad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, 30, 128)           2560000   \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 30, 128)           0         \n",
      "_________________________________________________________________\n",
      "lstm_5 (LSTM)                (None, 30, 196)           254800    \n",
      "_________________________________________________________________\n",
      "lstm_6 (LSTM)                (None, 98)                115640    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 2)                 198       \n",
      "=================================================================\n",
      "Total params: 2,930,638\n",
      "Trainable params: 2,930,638\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "embed_dim = 128 #128\n",
    "lstm_out = 196 #196\n",
    "lstm_out2 = 98\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, embed_dim,input_length = X.shape[1]))\n",
    "model.add(Dropout(0.5, noise_shape=None, seed=None))\n",
    "model.add(LSTM(lstm_out, dropout=0.5, recurrent_dropout=0.5,return_sequences=True))\n",
    "model.add(LSTM(lstm_out2, dropout=0.5, recurrent_dropout=0.5))\n",
    "model.add(Dense(2,activation='softmax'))\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer= 'adam' ,metrics = ['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(34447, 30) (34447, 2)\n",
      "(3828, 30) (3828, 2)\n"
     ]
    }
   ],
   "source": [
    "Y = pd.get_dummies(data['sent']).values\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size = 0.1, random_state = 42)\n",
    "print(X_train.shape,Y_train.shape)\n",
    "print(X_test.shape,Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "90s - loss: 0.6461 - acc: 0.6145\n",
      "Epoch 2/10\n",
      "89s - loss: 0.5284 - acc: 0.7406\n",
      "Epoch 3/10\n",
      "89s - loss: 0.4624 - acc: 0.7852\n",
      "Epoch 4/10\n",
      "89s - loss: 0.4185 - acc: 0.8107\n",
      "Epoch 5/10\n",
      "89s - loss: 0.3870 - acc: 0.8304\n",
      "Epoch 6/10\n",
      "89s - loss: 0.3591 - acc: 0.8445\n",
      "Epoch 7/10\n",
      "89s - loss: 0.3395 - acc: 0.8561\n",
      "Epoch 8/10\n",
      "89s - loss: 0.3210 - acc: 0.8651\n",
      "Epoch 9/10\n",
      "89s - loss: 0.2991 - acc: 0.8744\n",
      "Epoch 10/10\n",
      "89s - loss: 0.2836 - acc: 0.8839\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f06de1f4048>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 512\n",
    "model.fit(X_train, Y_train, epochs = 10, batch_size=batch_size, verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 2, got 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-77-e5c68853e64a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mX_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvalidation_size\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mY_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mY_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvalidation_size\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mscore\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"score: %.2f\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"acc: %.2f\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0macc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 2, got 0)"
     ]
    }
   ],
   "source": [
    "validation_size = 5000\n",
    "\n",
    "X_validate = X_test[0:validation_size]\n",
    "Y_validate = Y_test[0:validation_size]\n",
    "X_test = X_test[validation_size:]\n",
    "Y_test = Y_test[validation_size:]\n",
    "score,acc = model.evaluate(X_test, Y_test, verbose = 1, batch_size = batch_size)\n",
    "print(\"score: %.2f\" % (score))\n",
    "print(\"acc: %.2f\" % (acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.89100832  0.10899167]]\n"
     ]
    }
   ],
   "source": [
    "text = 'Questa recensione sarebbe incredibilmente brutta e cattiva'\n",
    "text = [text]\n",
    "text = tokenizer.texts_to_sequences(text)\n",
    "#print(text)\n",
    "text = pad_sequences(text, maxlen = 30)\n",
    "\n",
    "print(model.predict(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 2, got 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-79-ef5ffe74435a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mscore\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_validate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_validate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"score: %.2f\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"acc: %.2f\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0macc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 2, got 0)"
     ]
    }
   ],
   "source": [
    "score,acc = model.evaluate(X_validate, Y_validate, verbose = 1, batch_size = batch_size)\n",
    "print(\"score: %.2f\" % (score))\n",
    "print(\"acc: %.2f\" % (acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save('ItalianSentCls.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30000/30000 [==============================] - 27s    \n",
      "score: 0.69\n",
      "acc: 0.71\n"
     ]
    }
   ],
   "source": [
    "X_kaggle = data_kaggle_test['text'].values\n",
    "X_kaggle = tokenizer.texts_to_sequences(data_kaggle_test['text'].values)\n",
    "X_kaggle = pad_sequences(X_kaggle, maxlen=maxlen)\n",
    "Y_kaggle = pd.get_dummies(data_kaggle_test['sent']).values\n",
    "score,acc = model.evaluate(X_kaggle, Y_kaggle, verbose = 1, batch_size = batch_size)\n",
    "print(\"score: %.2f\" % (score))\n",
    "print(\"acc: %.2f\" % (acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.88036573  0.11963426]\n",
      "212\n",
      "[ 0.0289597   0.97104025]\n",
      "460\n",
      "[ 0.78312361  0.2168764 ]\n",
      "917\n",
      "[ 0.95555609  0.04444389]\n",
      "1381\n",
      "[ 0.84579498  0.15420507]\n",
      "1595\n",
      "[ 0.17350626  0.82649374]\n",
      "1721\n",
      "[ 0.50311816  0.49688181]\n",
      "5340\n",
      "[ 0.64528531  0.35471466]\n",
      "6403\n",
      "[ 0.19257914  0.80742091]\n",
      "8647\n",
      "[ 0.76830024  0.23169969]\n",
      "9973\n",
      "[ 0.96278     0.03721996]\n",
      "11451\n",
      "[ 0.02725658  0.97274345]\n",
      "13782\n",
      "[ 0.55383998  0.44616002]\n",
      "14352\n",
      "[ 0.98078096  0.01921897]\n",
      "15136\n",
      "[ 0.48755473  0.51244527]\n",
      "16520\n",
      "[ 0.01635754  0.98364246]\n",
      "18782\n",
      "[ 0.00571895  0.99428105]\n",
      "18863\n",
      "[ 0.59254622  0.40745381]\n",
      "19574\n",
      "[ 0.54189199  0.45810807]\n",
      "19614\n",
      "[ 0.9176957   0.08230425]\n",
      "20540\n",
      "[ 0.11549599  0.88450402]\n",
      "22888\n",
      "[ 0.06550961  0.93449038]\n",
      "23349\n",
      "[ 0.76443845  0.23556159]\n",
      "24845\n",
      "[ 0.05472164  0.94527835]\n",
      "25111\n",
      "[ 0.77383697  0.22616297]\n",
      "25532\n",
      "[ 0.93650693  0.06349311]\n",
      "26570\n",
      "[ 0.27035025  0.72964972]\n",
      "27742\n",
      "[ 0.85287827  0.1471217 ]\n",
      "28165\n",
      "[ 0.05102026  0.94897974]\n",
      "28784\n",
      "pos_acc 76.73904688700999 % 10408\n",
      "neg_acc 78.73453853472883 % 10510\n"
     ]
    }
   ],
   "source": [
    "pos_cnt, neg_cnt, pos_correct, neg_correct = 0, 0, 0, 0\n",
    "for x in range(len(X_kaggle)):\n",
    "    \n",
    "    result = model.predict(X_kaggle[x].reshape(1,X_test.shape[1]),batch_size=1,verbose = 2)[0]\n",
    "    \n",
    "    if random.uniform(0, 1) < 0.001:\n",
    "        print(result)\n",
    "        print(x)\n",
    "    \n",
    "    if result[0]>result[1]:\n",
    "        conf = result[0]\n",
    "    else:\n",
    "        conf = result[1]\n",
    "   \n",
    "    if conf > 0.80:\n",
    "        if np.argmax(result) == np.argmax(Y_kaggle[x]):\n",
    "            if np.argmax(Y_kaggle[x]) == 0:\n",
    "                neg_correct += 1\n",
    "            else:\n",
    "                pos_correct += 1\n",
    "\n",
    "        if np.argmax(Y_kaggle[x]) == 0:\n",
    "            neg_cnt += 1\n",
    "        else:\n",
    "            pos_cnt += 1\n",
    "\n",
    "\n",
    "\n",
    "print(\"pos_acc\", pos_correct/pos_cnt*100, \"%\", pos_cnt)\n",
    "print(\"neg_acc\", neg_correct/neg_cnt*100, \"%\", neg_cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600/600 [==============================] - 0s     \n",
      "score: 0.71\n",
      "acc: 0.72\n"
     ]
    }
   ],
   "source": [
    "X_data_pol_test = data_pol_test['text'].values\n",
    "X_data_pol_test = tokenizer.texts_to_sequences(data_pol_test['text'].values)\n",
    "X_data_pol_test = pad_sequences(X_data_pol_test, maxlen=maxlen)\n",
    "Y_data_pol_test = pd.get_dummies(data_pol_test['sent']).values\n",
    "score,acc = model.evaluate(X_data_pol_test, Y_data_pol_test, verbose = 1, batch_size = batch_size)\n",
    "print(\"score: %.2f\" % (score))\n",
    "print(\"acc: %.2f\" % (acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.00139925  0.99860078]\n",
      "288\n",
      "[ 0.72610384  0.27389619]\n",
      "363\n",
      "[ 0.00853224  0.99146771]\n",
      "452\n",
      "pos_acc 81.3953488372093 % 215\n",
      "neg_acc 72.35023041474655 % 217\n"
     ]
    }
   ],
   "source": [
    "pos_cnt, neg_cnt, pos_correct, neg_correct = 0, 0, 0, 0\n",
    "for x in range(len(X_data_pol_test)):\n",
    "    \n",
    "    result = model.predict(X_data_pol_test[x].reshape(1,X_test.shape[1]),batch_size=1,verbose = 2)[0]\n",
    "    \n",
    "    if random.uniform(0, 1) < 0.001:\n",
    "        print(result)\n",
    "        print(x)\n",
    "    \n",
    "    if result[0]>result[1]:\n",
    "        conf = result[0]\n",
    "    else:\n",
    "        conf = result[1]\n",
    "   \n",
    "    if conf > 0.80:\n",
    "        if np.argmax(result) == np.argmax(Y_data_pol_test[x]):\n",
    "            if np.argmax(Y_data_pol_test[x]) == 0:\n",
    "                neg_correct += 1\n",
    "            else:\n",
    "                pos_correct += 1\n",
    "\n",
    "        if np.argmax(Y_kaggle[x]) == 0:\n",
    "            neg_cnt += 1\n",
    "        else:\n",
    "            pos_cnt += 1\n",
    "\n",
    "\n",
    "\n",
    "print(\"pos_acc\", pos_correct/pos_cnt*100, \"%\", pos_cnt)\n",
    "print(\"neg_acc\", neg_correct/neg_cnt*100, \"%\", neg_cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "                                                   text  sent\n",
      "600   #lapo va in giro con una Jeep e il #governo #m...   0.0\n",
      "601   @dalila_di questo governo Monti mi piace quasi...   0.0\n",
      "602          @catwomanx11 noooo dopo nn c'Ã¨ piÃ¹ gusto   0.0\n",
      "603   BRAVO Pietro Ichino | I MIEI VOTI SULLA MANOVR...   1.0\n",
      "604   UnitiNellaPreghiera! RT @Chiarentino: un caffÃ...   1.0\n",
      "605   Toh hanno scongelato anche la  Santanche' stas...   0.0\n",
      "606   Rubare ai 'poveri' per dare alle ricche banche...   0.0\n",
      "607   Il Governo #Monti dovrebbe ringraziare la #Con...   0.0\n",
      "608             @Melodika82 bella foto . Fa molto relax   1.0\n",
      "609   RT @vitocontesi: TU..VUOI RESTARE AL COLLE??OK...   0.0\n",
      "610   RT @andre_farewell: #ConfessioniUltime di @Cor...   1.0\n",
      "611     voglia di partire e mandare a tutti a fanculo..   0.0\n",
      "612   LâItalia dei valori...Lidia Undemi, nauseata...   0.0\n",
      "613   L'amore Ã¨ una roccia. Le lacrime che scendera...   0.0\n",
      "614   Voglio essere ottimista: Mario Monti mi ha spi...   1.0\n",
      "615   @DinoGiarrusso e dopo #Grillo mago otelma; tan...   0.0\n",
      "616   Ferrara stronca Mario Monti: \"Da lui ovvietÃ ,...   0.0\n",
      "617   la lega va all'opposizione, il pd si suicida i...   0.0\n",
      "618   @Idvstaff @tweetpolitica sicuramente il #Gover...   1.0\n",
      "619   Startup italiane forza, Ã¨ il vostro momento! ...   1.0\n",
      "620   Avanti, non ha tutti i torti! XD &gt; #DAlema:...   0.0\n",
      "621               @mazzmarco4 che amore che Ã¨!!!!!!!!!   1.0\n",
      "622   Freddo Freddo Freddo Freddo Freddo Freddo Fred...   0.0\n",
      "623   Su Rete 4 c'Ã¨ La Stangata. Quella vera, non q...   0.0\n",
      "624              @onedftunionj la distanza fa schifo,gn   0.0\n",
      "625   Nessuno dei #ministri del governo #monti Ã© de...   0.0\n",
      "626                                    Oh ma vaffanculo   0.0\n",
      "627   RT @ineedmyidolshug: Io mi chiedo ancora cosa ...   0.0\n",
      "628   A Matteo Renzi piace Mario Monti e viceversa. ...   0.0\n",
      "629   #Grillo l'elogio alla follia, #Sallusti l'elog...   0.0\n",
      "...                                                 ...   ...\n",
      "3272               @LCuccarini Bello! Buona giornata:-)   1.0\n",
      "3273  Vogliamo il Presidente Mario Monti http://t.co...   1.0\n",
      "3274  Lei ha una voce con i controcazzi.  #italiasgo...   1.0\n",
      "3275  RT @Abocconetti: Se #Grillo Ã¨ l'alternativa m...   0.0\n",
      "3276  Coglione muoviti :'3 ho fatto le corse per te ...   0.0\n",
      "3277  L'Eurogruppo saluta la Â«notevole performanceÂ...   1.0\n",
      "3278  La gente incolpa #Grillo persino del debito pu...   0.0\n",
      "3279  @englishipster si, perchÃ© i miei non hanno la...   1.0\n",
      "3280  @TeoOrlando ci pensa #Grillo a farsi le vacanz...   0.0\n",
      "3281  #siamonoi che andremo a vivere sotto i ponti e...   0.0\n",
      "3282  @jadepiper4 dovrebbe essere tranquillo questa ...   1.0\n",
      "3283  In qst giorni in #Italia, nn va bene niente......   0.0\n",
      "3284                   @clandestina0204 buongiorno cara   1.0\n",
      "3285  #Renzi Spero che il governo Monti arrivi fino ...   1.0\n",
      "3286  #piazza pulita #Grillo e' bravo a fare lo show...   0.0\n",
      "3287  @cates86 no lo so che non Ã¨ facile, altriment...   0.0\n",
      "3288   #Postofisso che #monotonia : Twitter attacca ...   0.0\n",
      "3289  #Passera per il governo Monti. Non Ã¨ che berl...   0.0\n",
      "3290  \\\"Ti amo da qui... Alla fine del monfo... Di n...   1.0\n",
      "3291  Mario Monti mi sta giÃ  sul cazzo, oltre a non...   0.0\n",
      "3292                           Governo Monti= dittatura   0.0\n",
      "3293  Governo Monti, Fini: \"Ministri di grande compe...   1.0\n",
      "3294  Mario #Monti Da Goldman Sachs ad Aspen Institu...   0.0\n",
      "3295  In Rai moltissimi ritrovano il gusto per la sa...   0.0\n",
      "3296  RT @Ila_iaia_: #AnnalisaWonTheInternationalSon...   1.0\n",
      "3297      @flavia_marzano Mario Monti dice le parolacce   1.0\n",
      "3298  Se si va avanti cosÃ¬, fra 3 mesi la benzina c...   0.0\n",
      "3299  Alzarsi tardi la mattina quando c'Ã¨ scuola e ...   1.0\n",
      "3300  MARIO MONTI L'ALIENO: GODETEVELO ANCORA PER PO...   0.0\n",
      "3301  il fatto che #Grillo sia osteggiato da tutti i...   1.0\n",
      "\n",
      "[2702 rows x 2 columns]\n",
      "0.0    1402\n",
      "1.0    1300\n",
      "Name: sent, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "X_data_pol_train = data_pol_train['text'].values\n",
    "X_data_pol_train = tokenizer.texts_to_sequences(data_pol_train['text'].values)\n",
    "X_data_pol_train = pad_sequences(X_data_pol_train, maxlen=maxlen)\n",
    "Y_data_pol_train = pd.get_dummies(data_pol_train['sent']).values\n",
    "diff = data_pol['sent'].value_counts()[0] - data_pol['sent'].value_counts()[1]\n",
    "print (diff)\n",
    "print(data_pol_train)\n",
    "    \n",
    "print(data_pol_train['sent'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "9s - loss: 0.1400 - acc: 0.8488\n",
      "Epoch 2/2\n",
      "9s - loss: 0.1147 - acc: 0.8607\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f0713c2c3c8>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 512\n",
    "model.fit(X_data_pol_train, Y_data_pol_train, epochs = 2, batch_size=batch_size, verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
