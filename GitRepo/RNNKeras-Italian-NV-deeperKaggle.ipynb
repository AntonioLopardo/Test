{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import keras\n",
    "import pickle\n",
    "import json\n",
    "import os\n",
    "import random\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, LSTM, Dropout\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras import optimizers\n",
    "import re\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.6\n"
     ]
    }
   ],
   "source": [
    "print(keras.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = tf.ConfigProto( device_count = {'GPU': 1 , 'CPU': 4} ) \n",
    "sess = tf.Session(config=config) \n",
    "keras.backend.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame([['fuck you, life is shitty', 0]], columns=['text', 'sent'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   A  B\n",
       "0  1  2"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame([[1, 2], [3, 4]], columns=list('AB'))\n",
    "df = df[df['B'] == 2]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    39822\n",
      "0    31435\n",
      "Name: sent, dtype: int64\n",
      "8387\n",
      "1    16493\n",
      "0    16377\n",
      "Name: sent, dtype: int64\n",
      "0    15058\n",
      "1    14942\n",
      "Name: sent, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "data_kaggle = pd.read_csv('training_data/KaggleTranslated.csv', encoding='latin_1', index_col = 0)\n",
    "data_kaggle = data_kaggle.rename(index=str, columns={\"SentimentText\": \"text\"})\n",
    "\n",
    "print(data_kaggle['sent'].value_counts())\n",
    "\n",
    "diff = abs(data_kaggle['sent'].value_counts()[0] - data_kaggle['sent'].value_counts()[1])\n",
    "print (diff)\n",
    "\n",
    "data_kaggle_pos = data_kaggle[data_kaggle['sent'] == 1]\n",
    "\n",
    "drop_indices = np.random.choice(data_kaggle_pos.index, diff, replace=False)\n",
    "\n",
    "data_kaggle = data_kaggle.drop(drop_indices)\n",
    "\n",
    "data_kaggle = data_kaggle.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "data_kaggle_test = data_kaggle[data_kaggle.index < 30000]\n",
    "data_kaggle_train = data_kaggle[data_kaggle.index >= 30000]\n",
    "    \n",
    "print(data_kaggle_train['sent'].value_counts())\n",
    "print(data_kaggle_test['sent'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0    2472\n",
      "1.0    1601\n",
      "Name: sent, dtype: int64\n",
      "871\n",
      "0.0    1701\n",
      "1.0    1601\n",
      "Name: sent, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "data_pol = pd.read_csv('training_data/training_set_sentipolc16.csv', encoding = \"latin_1\")\n",
    "del data_pol['idtwitter']\n",
    "del data_pol['iro']\n",
    "del data_pol['top']\n",
    "del data_pol['subj']\n",
    "\n",
    "data_pol = data_pol.drop(data_pol[(data_pol['opos'] == 1) & (data_pol['oneg'] == 1)].index)\n",
    "data_pol = data_pol.drop(data_pol[(data_pol['lpos'] == 1) & (data_pol['lneg'] == 1)].index)\n",
    "\n",
    "data_pol.loc[data_pol['lpos'] == 1, 'sent'] = 1\n",
    "data_pol.loc[data_pol['lneg'] == 1, 'sent'] = 0\n",
    "\n",
    "data_pol.loc[data_pol['opos'] == 1, 'sent'] = 1\n",
    "data_pol.loc[data_pol['oneg'] == 1, 'sent'] = 0\n",
    "\n",
    "\n",
    "data_pol = data_pol[['text','sent']]\n",
    "\n",
    "print(data_pol['sent'].value_counts())\n",
    "\n",
    "diff = data_pol['sent'].value_counts()[0] - data_pol['sent'].value_counts()[1]\n",
    "print (diff)\n",
    "d_neg = data_pol[data_pol['sent'] == 0]\n",
    "\n",
    "drop_indices = np.random.choice(d_neg.index, diff-100, replace=False)\n",
    "\n",
    "data_pol = data_pol.drop(drop_indices)\n",
    "    \n",
    "print(data_pol['sent'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0    314\n",
      "0.0    286\n",
      "Name: sent, dtype: int64\n",
      "0.0    1415\n",
      "1.0    1287\n",
      "Name: sent, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "data_pol = data_pol.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "data_null = data_pol[np.isnan(data_pol['sent'])]\n",
    "drop_indices = np.random.choice(data_null.index, data_null.shape[0], replace=False)\n",
    "\n",
    "data_pol = data_pol.drop(drop_indices)\n",
    "\n",
    "data_pol = data_pol.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "data_pol_test = data_pol[data_pol.index < 600]\n",
    "data_pol_train = data_pol[data_pol.index >= 600]\n",
    "\n",
    "\n",
    "print(data_pol_test['sent'].value_counts())\n",
    "print(data_pol_train['sent'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0    19208\n",
      "1.0    19067\n",
      "Name: sent, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "data_pol = data_pol.sample(frac=1).reset_index(drop=True)\n",
    "data = data.append(data_kaggle_train,ignore_index=True)\n",
    "data = data.append(data_pol_train,  ignore_index=True)\n",
    "data = data.append(data_pol_train,  ignore_index=True)\n",
    "\n",
    "print(data['sent'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0    19208\n",
      "1.0    19067\n",
      "Name: sent, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "data['text'] = data['text'].apply(lambda x: x.lower())\n",
    "data['text'] = data['text'].apply((lambda x: re.sub('[^a-zA-z0-9\\s]','',x)))\n",
    "data['text'] = data['text'].apply((lambda x: re.sub(':\\)','',x)))\n",
    "data['text'] = data['text'].apply((lambda x: re.sub(':\\(','',x)))\n",
    "data['text'] = data['text'].apply((lambda x: re.sub('#','',x)))\n",
    "data['text'] = data['text'].apply((lambda x: re.sub('Berlusconi','akfha',x)))\n",
    "data['text'] = data['text'].apply((lambda x: re.sub('Renzi','lafh',x)))\n",
    "data['text'] = data['text'].apply((lambda x: re.sub('Salvini','kjahfka',x)))\n",
    "data['text'] = data['text'].apply((lambda x: re.sub('Grillo','lhalahfl',x)))\n",
    "data['text'] = data['text'].apply((lambda x: re.sub('berlusconi','akfha',x)))\n",
    "data['text'] = data['text'].apply((lambda x: re.sub('renzi','lafh',x)))\n",
    "data['text'] = data['text'].apply((lambda x: re.sub('salvini','kjahfka',x)))\n",
    "data['text'] = data['text'].apply((lambda x: re.sub('grillo','lhalahfl',x)))\n",
    "data['text'] = data['text'].apply((lambda x: re.sub('Lega','sds',x)))\n",
    "data['text'] = data['text'].apply((lambda x: re.sub('PD ','fsfsfsf',x)))\n",
    "data['text'] = data['text'].apply((lambda x: re.sub('FI ','dsgsgsgs',x)))\n",
    "\n",
    "print(data['sent'].value_counts())\n",
    "\n",
    "data = data.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "num_words = 20000\n",
    "maxlen = 30\n",
    "tokenizer = Tokenizer(num_words=num_words, split=' ')\n",
    "tokenizer.fit_on_texts(data['text'].values)\n",
    "tweets = tokenizer.texts_to_sequences(data['text'].values)\n",
    "tweets = pad_sequences(tweets, maxlen=maxlen)\n",
    "\n",
    "tokenizer_file = open(\"model_files/tokenizer.pickle\", \"wb\")\n",
    "pickle.dump(tokenizer, tokenizer_file)\n",
    "tokenizer_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_10 (Embedding)     (None, 30, 128)           2560000   \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 30, 128)           0         \n",
      "_________________________________________________________________\n",
      "lstm_19 (LSTM)               (None, 30, 196)           254800    \n",
      "_________________________________________________________________\n",
      "lstm_20 (LSTM)               (None, 98)                115640    \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 2)                 198       \n",
      "=================================================================\n",
      "Total params: 2,930,638\n",
      "Trainable params: 2,930,638\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "emb_dim = 128 #128\n",
    "lstm_size = 196 #196\n",
    "lstm2_size = 98\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(num_words, emb_dim,input_length = tweets.shape[1]))\n",
    "model.add(Dropout(0.5, noise_shape=None, seed=None))\n",
    "model.add(LSTM(lstm_size, dropout=0.5, recurrent_dropout=0.5,return_sequences=True))\n",
    "model.add(LSTM(lstm2_size, dropout=0.5, recurrent_dropout=0.5))\n",
    "model.add(Dense(2,activation='softmax'))\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer= 'adam' ,metrics = ['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(34447, 30) (34447, 2)\n",
      "(3828, 30) (3828, 2)\n"
     ]
    }
   ],
   "source": [
    "labels = pd.get_dummies(data['sent']).values\n",
    "tweets_train, tweets_test, labels_train, labels_test = train_test_split(tweets,labels, test_size = 0.1, random_state = 42)\n",
    "print(tweets_train.shape,labels_train.shape)\n",
    "print(tweets_test.shape,labels_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/7\n",
      "12s - loss: 0.6484 - acc: 0.6157\n",
      "Epoch 2/7\n",
      "10s - loss: 0.5340 - acc: 0.7374\n",
      "Epoch 3/7\n",
      "10s - loss: 0.4656 - acc: 0.7857\n",
      "Epoch 4/7\n",
      "10s - loss: 0.4198 - acc: 0.8107\n",
      "Epoch 5/7\n",
      "10s - loss: 0.3872 - acc: 0.8280\n",
      "Epoch 6/7\n",
      "10s - loss: 0.3650 - acc: 0.8423\n",
      "Epoch 7/7\n",
      "10s - loss: 0.3456 - acc: 0.8520\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe8c7229f60>"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 512\n",
    "model.fit(tweets_train, labels_train, epochs = 7, batch_size=batch_size, verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3072/3328 [==========================>...] - ETA: 0sscore: 0.57\n",
      "acc: 0.74\n"
     ]
    }
   ],
   "source": [
    "validation_size = 500\n",
    "\n",
    "tweets_validate = tweets_test[0:validation_size]\n",
    "labels_validate = labels_test[0:validation_size]\n",
    "tweets_test = tweets_test[validation_size:]\n",
    "labels_test = labels_test[validation_size:]\n",
    "score,acc = model.evaluate(tweets_test, labels_test, verbose = 1, batch_size = batch_size)\n",
    "print(\"score: %.2f\" % (score))\n",
    "print(\"acc: %.2f\" % (acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500/500 [==============================] - 0s\n",
      "score: 0.50\n",
      "acc: 0.78\n"
     ]
    }
   ],
   "source": [
    "score,acc = model.evaluate(tweets_validate, labels_validate, verbose = 1, batch_size = batch_size)\n",
    "print(\"score: %.2f\" % (score))\n",
    "print(\"acc: %.2f\" % (acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model_files/ItalianSentCls.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29696/30000 [============================>.] - ETA: 0sscore: 0.61\n",
      "acc: 0.72\n"
     ]
    }
   ],
   "source": [
    "tweets_kaggle = data_kaggle_test['text'].values\n",
    "tweets_kaggle = tokenizer.texts_to_sequences(data_kaggle_test['text'].values)\n",
    "tweets_kaggle = pad_sequences(tweets_kaggle, maxlen=maxlen)\n",
    "labels_kaggle = pd.get_dummies(data_kaggle_test['sent']).values\n",
    "score,acc = model.evaluate(tweets_kaggle, labels_kaggle, verbose = 1, batch_size = batch_size)\n",
    "print(\"score: %.2f\" % (score))\n",
    "print(\"acc: %.2f\" % (acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.2184135  0.78158647]\n",
      "2482\n",
      "[0.04721038 0.95278966]\n",
      "4158\n",
      "[0.02263385 0.9773662 ]\n",
      "6798\n",
      "[0.03695268 0.96304727]\n",
      "11987\n",
      "[0.43978882 0.5602112 ]\n",
      "12820\n",
      "[0.04812514 0.9518749 ]\n",
      "16333\n",
      "[0.01602385 0.9839761 ]\n",
      "17151\n",
      "[0.64830303 0.35169703]\n",
      "22198\n",
      "[0.963292   0.03670794]\n",
      "24619\n",
      "[0.23398651 0.7660135 ]\n",
      "29754\n",
      "pos_acc 76.08521704340868 % 9998\n",
      "neg_acc 81.07770627221208 % 10411\n"
     ]
    }
   ],
   "source": [
    "pos_cnt, neg_cnt, pos_correct, neg_correct = 0, 0, 0, 0\n",
    "for x in range(len(tweets_kaggle)):    \n",
    "    result = model.predict(tweets_kaggle[x].reshape(1,tweets_test.shape[1]),batch_size=1,verbose = 2)[0]   \n",
    "    if random.uniform(0, 1) < 0.0003:\n",
    "        print(result)\n",
    "        print(x)   \n",
    "    if result[0]>result[1]:\n",
    "        conf = result[0]\n",
    "    else:\n",
    "        conf = result[1]   \n",
    "    if conf > 0.80:\n",
    "        if np.argmax(result) == np.argmax(labels_kaggle[x]):\n",
    "            if np.argmax(labels_kaggle[x]) == 0:\n",
    "                neg_correct += 1\n",
    "            else:\n",
    "                pos_correct += 1\n",
    "\n",
    "        if np.argmax(labels_kaggle[x]) == 0:\n",
    "            neg_cnt += 1\n",
    "        else:\n",
    "            pos_cnt += 1\n",
    "\n",
    "print(\"pos_acc\", pos_correct/pos_cnt*100, \"%\", pos_cnt)\n",
    "print(\"neg_acc\", neg_correct/neg_cnt*100, \"%\", neg_cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512/600 [========================>.....] - ETA: 0sscore: 0.61\n",
      "acc: 0.74\n"
     ]
    }
   ],
   "source": [
    "tweets_data_pol_test = data_pol_test['text'].values\n",
    "tweets_data_pol_test = tokenizer.texts_to_sequences(data_pol_test['text'].values)\n",
    "tweets_data_pol_test = pad_sequences(tweets_data_pol_test, maxlen=maxlen)\n",
    "labels_data_pol_test = pd.get_dummies(data_pol_test['sent']).values\n",
    "score,acc = model.evaluate(tweets_data_pol_test, labels_data_pol_test, verbose = 1, batch_size = batch_size)\n",
    "print(\"score: %.2f\" % (score))\n",
    "print(\"acc: %.2f\" % (acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "0.0    1415\n",
      "1.0    1287\n",
      "Name: sent, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "tweets_data_pol_train = data_pol_train['text'].values\n",
    "tweets_data_pol_train = tokenizer.texts_to_sequences(data_pol_train['text'].values)\n",
    "tweets_data_pol_train = pad_sequences(tweets_data_pol_train, maxlen=maxlen)\n",
    "labels_data_pol_train = pd.get_dummies(data_pol_train['sent']).values\n",
    "diff = data_pol['sent'].value_counts()[0] - data_pol['sent'].value_counts()[1]\n",
    "print (diff)\n",
    "    \n",
    "print(data_pol_train['sent'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "0s - loss: 0.2347 - acc: 0.9164\n",
      "Epoch 2/2\n",
      "0s - loss: 0.2107 - acc: 0.9152\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe8c1c71400>"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 512\n",
    "model.fit(tweets_data_pol_train, labels_data_pol_train, epochs = 2, batch_size=batch_size, verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5665237  0.43347627]\n",
      "22\n",
      "[0.97419894 0.025801  ]\n",
      "54\n",
      "pos_acc 85.86387434554975 % 191\n",
      "neg_acc 78.80184331797236 % 217\n"
     ]
    }
   ],
   "source": [
    "pos_cnt, neg_cnt, pos_correct, neg_correct = 0, 0, 0, 0\n",
    "for x in range(len(tweets_data_pol_test)):\n",
    "    \n",
    "    result = model.predict(tweets_data_pol_test[x].reshape(1,tweets_test.shape[1]),batch_size=1,verbose = 2)[0]\n",
    "    \n",
    "    if random.uniform(0, 1) < 0.001:\n",
    "        print(result)\n",
    "        print(x)\n",
    "    \n",
    "    if result[0]>result[1]:\n",
    "        conf = result[0]\n",
    "    else:\n",
    "        conf = result[1]\n",
    "   \n",
    "    if conf > 0.80:\n",
    "        if np.argmax(result) == np.argmax(labels_data_pol_test[x]):\n",
    "            if np.argmax(labels_data_pol_test[x]) == 0:\n",
    "                neg_correct += 1\n",
    "            else:\n",
    "                pos_correct += 1\n",
    "\n",
    "        if np.argmax(labels_kaggle[x]) == 0:\n",
    "            neg_cnt += 1\n",
    "        else:\n",
    "            pos_cnt += 1\n",
    "\n",
    "\n",
    "\n",
    "print(\"pos_acc\", pos_correct/pos_cnt*100, \"%\", pos_cnt)\n",
    "print(\"neg_acc\", neg_correct/neg_cnt*100, \"%\", neg_cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.8881522  0.11184778]]\n"
     ]
    }
   ],
   "source": [
    "text = 'Questa recensione sarebbe incredibilmente brutta e cattiva'\n",
    "text = [text]\n",
    "text = tokenizer.texts_to_sequences(text)\n",
    "text = pad_sequences(text, maxlen = 30)\n",
    "\n",
    "print(model.predict(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
