{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import keras\n",
    "import pickle\n",
    "import json\n",
    "import os\n",
    "import random\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, LSTM, Dropout\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras import optimizers\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.6\n"
     ]
    }
   ],
   "source": [
    "print(keras.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#forcing keras to use the gpu\n",
    "config = tf.ConfigProto( device_count = {'GPU': 1 , 'CPU': 4} ) \n",
    "sess = tf.Session(config=config) \n",
    "keras.backend.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#inizialization of the dataset\n",
    "data = pd.DataFrame([['tweet molto negativo', 0]], columns=['text', 'sent'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    39822\n",
      "0    31435\n",
      "Name: sent, dtype: int64\n",
      "8387\n",
      "1    21545\n",
      "0    21325\n",
      "Name: sent, dtype: int64\n",
      "0    10110\n",
      "1     9890\n",
      "Name: sent, dtype: int64\n",
      "220\n",
      "0    21325\n",
      "1    21275\n",
      "Name: sent, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#loading the data from the KaggleTranslated dataset\n",
    "data_kaggle = pd.read_csv('training_data/KaggleTranslated.csv', encoding='latin_1', index_col = 0)\n",
    "data_kaggle = data_kaggle.rename(index=str, columns={\"SentimentText\": \"text\"})\n",
    "\n",
    "print(data_kaggle['sent'].value_counts())\n",
    "\n",
    "diff = abs(data_kaggle['sent'].value_counts()[0] - data_kaggle['sent'].value_counts()[1])\n",
    "print (diff)\n",
    "\n",
    "data_kaggle_pos = data_kaggle[data_kaggle['sent'] == 1]\n",
    "\n",
    "drop_indices = np.random.choice(data_kaggle_pos.index, diff, replace=False)\n",
    "\n",
    "data_kaggle = data_kaggle.drop(drop_indices) #balancing the dataset |pos| = |neg|\n",
    "\n",
    "data_kaggle = data_kaggle.sample(frac=1).reset_index(drop=True) #shuffling the dataset\n",
    "\n",
    "data_kaggle_test = data_kaggle[data_kaggle.index < 20000] #test-train split\n",
    "data_kaggle_train = data_kaggle[data_kaggle.index >= 20000]\n",
    "    \n",
    "print(data_kaggle_train['sent'].value_counts())\n",
    "print(data_kaggle_test['sent'].value_counts())\n",
    "\n",
    "diff = data_kaggle_train['sent'].value_counts()[1] - data_kaggle_train['sent'].value_counts()[0]\n",
    "print (diff)\n",
    "d_neg = data_kaggle_train[data_kaggle_train['sent'] == 1]\n",
    "\n",
    "drop_indices = np.random.choice(d_neg.index, diff+50, replace=False)\n",
    "\n",
    "data_kaggle_train = data_kaggle_train.drop(drop_indices)#balancing the dataset \n",
    "    \n",
    "print(data_kaggle_train['sent'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0    2472\n",
      "1.0    1601\n",
      "Name: sent, dtype: int64\n",
      "871\n",
      "0.0    1701\n",
      "1.0    1601\n",
      "Name: sent, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#loading data from sentipol16, data from an italian political sentiment competion\n",
    "data_pol = pd.read_csv('training_data/training_set_sentipolc16.csv', encoding = \"latin_1\")\n",
    "\n",
    "#deleting the unused collumns \n",
    "del data_pol['idtwitter'] \n",
    "del data_pol['iro']\n",
    "del data_pol['top']\n",
    "del data_pol['subj']\n",
    "\n",
    "#dropping mixed sentiment tweets\n",
    "data_pol = data_pol.drop(data_pol[(data_pol['opos'] == 1) & (data_pol['oneg'] == 1)].index)\n",
    "data_pol = data_pol.drop(data_pol[(data_pol['lpos'] == 1) & (data_pol['lneg'] == 1)].index)\n",
    "\n",
    "data_pol.loc[data_pol['lpos'] == 1, 'sent'] = 1\n",
    "data_pol.loc[data_pol['lneg'] == 1, 'sent'] = 0\n",
    "\n",
    "data_pol.loc[data_pol['opos'] == 1, 'sent'] = 1\n",
    "data_pol.loc[data_pol['oneg'] == 1, 'sent'] = 0\n",
    "\n",
    "\n",
    "data_pol = data_pol[['text','sent']]\n",
    "\n",
    "print(data_pol['sent'].value_counts())\n",
    "\n",
    "diff = data_pol['sent'].value_counts()[0] - data_pol['sent'].value_counts()[1]\n",
    "print (diff)\n",
    "d_neg = data_pol[data_pol['sent'] == 0]\n",
    "\n",
    "drop_indices = np.random.choice(d_neg.index, diff-100, replace=False)\n",
    "\n",
    "data_pol = data_pol.drop(drop_indices)#balancing the dataset \n",
    "    \n",
    "print(data_pol['sent'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0    250\n",
      "0.0    250\n",
      "Name: sent, dtype: int64\n",
      "0.0    1451\n",
      "1.0    1351\n",
      "Name: sent, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "data_pol = data_pol.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "data_null = data_pol[np.isnan(data_pol['sent'])]\n",
    "drop_indices = np.random.choice(data_null.index, data_null.shape[0], replace=False)\n",
    "\n",
    "data_pol = data_pol.drop(drop_indices)\n",
    "\n",
    "data_pol = data_pol.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "#train-test split\n",
    "data_pol_test = data_pol[data_pol.index < 500] \n",
    "data_pol_train = data_pol[data_pol.index >= 500]\n",
    "\n",
    "\n",
    "print(data_pol_test['sent'].value_counts())\n",
    "print(data_pol_train['sent'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0    24228\n",
      "1.0    23977\n",
      "Name: sent, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Combining the dataset,  \n",
    "data_pol = data_pol.sample(frac=1).reset_index(drop=True)\n",
    "data = data.append(data_kaggle_train,ignore_index=True)\n",
    "data = data.append(data_pol_train,  ignore_index=True)\n",
    "data = data.append(data_pol_train,  ignore_index=True)\n",
    "\n",
    "print(data['sent'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0    24228\n",
      "1.0    23977\n",
      "Name: sent, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Removing sensible words such as the names of candidates and parties\n",
    "data['text'] = data['text'].apply(lambda x: x.lower())\n",
    "data['text'] = data['text'].apply((lambda x: re.sub('[^a-zA-z0-9\\s]','',x)))\n",
    "data['text'] = data['text'].apply((lambda x: re.sub(':\\)','',x)))\n",
    "data['text'] = data['text'].apply((lambda x: re.sub(':\\(','',x)))\n",
    "data['text'] = data['text'].apply((lambda x: re.sub('#','',x)))\n",
    "data['text'] = data['text'].apply((lambda x: re.sub('Berlusconi','akfha',x)))\n",
    "data['text'] = data['text'].apply((lambda x: re.sub('Renzi','lafh',x)))\n",
    "data['text'] = data['text'].apply((lambda x: re.sub('Salvini','kjahfka',x)))\n",
    "data['text'] = data['text'].apply((lambda x: re.sub('Grillo','lhalahfl',x)))\n",
    "data['text'] = data['text'].apply((lambda x: re.sub('berlusconi','akfha',x)))\n",
    "data['text'] = data['text'].apply((lambda x: re.sub('renzi','lafh',x)))\n",
    "data['text'] = data['text'].apply((lambda x: re.sub('salvini','kjahfka',x)))\n",
    "data['text'] = data['text'].apply((lambda x: re.sub('grillo','lhalahfl',x)))\n",
    "data['text'] = data['text'].apply((lambda x: re.sub('Lega','sds',x)))\n",
    "data['text'] = data['text'].apply((lambda x: re.sub('PD ','fsfsfsf',x)))\n",
    "data['text'] = data['text'].apply((lambda x: re.sub('FI ','dsgsgsgs',x)))\n",
    "\n",
    "print(data['sent'].value_counts())\n",
    "\n",
    "data = data.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "#initializing the tokenizer\n",
    "num_words = 35000\n",
    "maxlen = 30\n",
    "tokenizer = Tokenizer(num_words=num_words, split=' ') \n",
    "tokenizer.fit_on_texts(data['text'].values)\n",
    "\n",
    "#tokening the dataset\n",
    "tweets = tokenizer.texts_to_sequences(data['text'].values)\n",
    "tweets = pad_sequences(tweets, maxlen=maxlen)\n",
    "\n",
    "#saving the tokenizer\n",
    "tokenizer_file = open(\"model_files/tokenizer.pickle\", \"wb\")\n",
    "pickle.dump(tokenizer, tokenizer_file)\n",
    "tokenizer_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, 30, 128)           4480000   \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 30, 128)           0         \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 196)               254800    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 2)                 394       \n",
      "=================================================================\n",
      "Total params: 4,735,194\n",
      "Trainable params: 4,735,194\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#building the model\n",
    "emb_dim = 128 #128\n",
    "lstm_size = 196 #196\n",
    "lstm2_size = 98\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(num_words, emb_dim,input_length = tweets.shape[1]))\n",
    "model.add(Dropout(0.5, noise_shape=None, seed=None))\n",
    "model.add(LSTM(lstm_size, dropout=0.5, recurrent_dropout=0.5))\n",
    "#model.add(LSTM(lstm2_size, dropout=0.1, recurrent_dropout=0.1,return_sequences=True))\n",
    "model.add(Dense(2,activation='softmax'))\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer= 'adam' ,metrics = ['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(43384, 30) (43384, 2)\n",
      "(4821, 30) (4821, 2)\n"
     ]
    }
   ],
   "source": [
    "labels = pd.get_dummies(data['sent']).values\n",
    "tweets_train, tweets_test, labels_train, labels_test = train_test_split(tweets,labels, test_size = 0.1, random_state = 42)\n",
    "print(tweets_train.shape,labels_train.shape)\n",
    "print(tweets_test.shape,labels_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6\n",
      "7s - loss: 0.6311 - acc: 0.6359\n",
      "Epoch 2/6\n",
      "7s - loss: 0.5095 - acc: 0.7541\n",
      "Epoch 3/6\n",
      "7s - loss: 0.4417 - acc: 0.8005\n",
      "Epoch 4/6\n",
      "7s - loss: 0.3938 - acc: 0.8263\n",
      "Epoch 5/6\n",
      "7s - loss: 0.3581 - acc: 0.8461\n",
      "Epoch 6/6\n",
      "7s - loss: 0.3256 - acc: 0.8614\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f1bf8320828>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 512\n",
    "model.fit(tweets_train, labels_train, epochs = 6, batch_size=batch_size, verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4321/4321 [==============================] - 0s     \n",
      "score: 0.55\n",
      "acc: 0.75\n"
     ]
    }
   ],
   "source": [
    "validation_size = 500\n",
    "\n",
    "tweets_validate = tweets_test[0:validation_size]\n",
    "labels_validate = labels_test[0:validation_size]\n",
    "tweets_test = tweets_test[validation_size:]\n",
    "labels_test = labels_test[validation_size:]\n",
    "score,acc = model.evaluate(tweets_test, labels_test, verbose = 1, batch_size = batch_size)\n",
    "print(\"score: %.2f\" % (score))\n",
    "print(\"acc: %.2f\" % (acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500/500 [==============================] - 0s\n",
      "score: 0.59\n",
      "acc: 0.76\n"
     ]
    }
   ],
   "source": [
    "score,acc = model.evaluate(tweets_validate, labels_validate, verbose = 1, batch_size = batch_size)\n",
    "print(\"score: %.2f\" % (score))\n",
    "print(\"acc: %.2f\" % (acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model_files/ItalianSentCls.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19968/20000 [============================>.] - ETA: 0sscore: 0.60\n",
      "acc: 0.73\n"
     ]
    }
   ],
   "source": [
    "tweets_kaggle = data_kaggle_test['text'].values\n",
    "tweets_kaggle = tokenizer.texts_to_sequences(data_kaggle_test['text'].values)\n",
    "tweets_kaggle = pad_sequences(tweets_kaggle, maxlen=maxlen)\n",
    "labels_kaggle = pd.get_dummies(data_kaggle_test['sent']).values\n",
    "score,acc = model.evaluate(tweets_kaggle, labels_kaggle, verbose = 1, batch_size = batch_size)\n",
    "print(\"score: %.2f\" % (score))\n",
    "print(\"acc: %.2f\" % (acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500/500 [==============================] - 0s\n",
      "score: 0.66\n",
      "acc: 0.70\n"
     ]
    }
   ],
   "source": [
    "tweets_data_pol_test = data_pol_test['text'].values\n",
    "tweets_data_pol_test = tokenizer.texts_to_sequences(data_pol_test['text'].values)\n",
    "tweets_data_pol_test = pad_sequences(tweets_data_pol_test, maxlen=maxlen)\n",
    "labels_data_pol_test = pd.get_dummies(data_pol_test['sent']).values\n",
    "score,acc = model.evaluate(tweets_data_pol_test, labels_data_pol_test, verbose = 1, batch_size = batch_size)\n",
    "print(\"score: %.2f\" % (score))\n",
    "print(\"acc: %.2f\" % (acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "0.0    1451\n",
      "1.0    1351\n",
      "Name: sent, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "tweets_data_pol_train = data_pol_train['text'].values\n",
    "tweets_data_pol_train = tokenizer.texts_to_sequences(data_pol_train['text'].values)\n",
    "tweets_data_pol_train = pad_sequences(tweets_data_pol_train, maxlen=maxlen)\n",
    "labels_data_pol_train = pd.get_dummies(data_pol_train['sent']).values\n",
    "diff = data_pol['sent'].value_counts()[0] - data_pol['sent'].value_counts()[1]\n",
    "print (diff)\n",
    "    \n",
    "print(data_pol_train['sent'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "0s - loss: 0.1728 - acc: 0.9404\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f1bf0836c88>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 512\n",
    "model.fit(tweets_data_pol_train, labels_data_pol_train, epochs = 1, batch_size=batch_size, verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.49862236 0.5013777 ]\n",
      "277\n",
      "pos_acc 77.63975155279503 % 161\n",
      "neg_acc 80.95238095238095 % 168\n"
     ]
    }
   ],
   "source": [
    "pos_cnt, neg_cnt, pos_correct, neg_correct = 0, 0, 0, 0\n",
    "for x in range(len(tweets_data_pol_test)):\n",
    "    \n",
    "    result = model.predict(tweets_data_pol_test[x].reshape(1,tweets_test.shape[1]),batch_size=1,verbose = 2)[0]\n",
    "    \n",
    "    if random.uniform(0, 1) < 0.001:\n",
    "        print(result)\n",
    "        print(x)\n",
    "    \n",
    "    if result[0]>result[1]:\n",
    "        conf = result[0]\n",
    "    else:\n",
    "        conf = result[1]\n",
    "   \n",
    "    if conf > 0.80:\n",
    "        if np.argmax(result) == np.argmax(labels_data_pol_test[x]):\n",
    "            if np.argmax(labels_data_pol_test[x]) == 0:\n",
    "                neg_correct += 1\n",
    "            else:\n",
    "                pos_correct += 1\n",
    "\n",
    "        if np.argmax(labels_kaggle[x]) == 0:\n",
    "            neg_cnt += 1\n",
    "        else:\n",
    "            pos_cnt += 1\n",
    "\n",
    "\n",
    "\n",
    "print(\"pos_acc\", pos_correct/pos_cnt*100, \"%\", pos_cnt)\n",
    "print(\"neg_acc\", neg_correct/neg_cnt*100, \"%\", neg_cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.78378767 0.21621233]]\n"
     ]
    }
   ],
   "source": [
    "text = 'Questa cosa Ã¨ molto negativa '\n",
    "text = [text]\n",
    "text = tokenizer.texts_to_sequences(text)\n",
    "text = pad_sequences(text, maxlen = 30)\n",
    "\n",
    "print(model.predict(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named 'Textblob'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-ee55f55ca49b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mTextblob\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m: No module named 'Textblob'"
     ]
    }
   ],
   "source": [
    "import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
